{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36024c72-6afd-429c-914e-0b6ed5a03b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "440167e4-7914-430f-8d03-6c28187a92f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.zeros((5, 3, 1024, 1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd5d7839-cd6b-4589-9368-29cb175e6d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from GNN.src.dnn_f import DNN_F\n",
    "model = DNN_F()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c2e2b6-0105-41cd-888b-83751965b48f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ab13746-5645-412f-b947-92b6f6564a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_Both.pkl             Test_VEGF.pkl             Train_VEGF_normalized.pkl\n",
      "Test_Both_normalized.pkl  Test_VEGF_normalized.pkl  Valid_Both_normalized.pkl\n",
      "Test_TER.pkl              Train_Both_normalized.pkl Valid_TER_normalized.pkl\n",
      "Test_TER_normalized.pkl   Train_TER_normalized.pkl  Valid_VEGF_normalized.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls \"../Data/FinalSplits/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48f4b727-ca65-4c79-8705-aadc10c207c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "def check_for_nan(dataset):\n",
    "    for i, data in enumerate(dataset):\n",
    "        if torch.isnan(data.x).any():\n",
    "            print(f\"NaN found in features at index {i}\")\n",
    "        if torch.isnan(data.y).any():\n",
    "            print(f\"NaN found in target at index {i}\")\n",
    "\n",
    "def load_dataset_from_pickle(pickle_file):\n",
    "    with open(pickle_file, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    if isinstance(dataset, list) and all(isinstance(d, Data) for d in dataset):\n",
    "        return dataset\n",
    "    else:\n",
    "        raise ValueError(\"The loaded dataset is not a list of Data objects).\")\n",
    "\n",
    "def get_loaders(data_dirs, target, batch_size, print_data_stats = True, print_detailed = False):\n",
    "    train_pickle_file = data_dirs[f\"Train_{target}\"]\n",
    "    val_pickle_file = data_dirs[f\"Valid_{target}\"]\n",
    "    test_pickle_file = data_dirs[f\"Test_{target}\"]\n",
    "\n",
    "    # train_dataset = load_dataset_from_pickle(train_pickle_file)\n",
    "    # val_dataset = load_dataset_from_pickle(val_pickle_file)\n",
    "    test_dataset = load_dataset_from_pickle(test_pickle_file)\n",
    "\n",
    "    # check_for_nan(train_dataset)\n",
    "    # check_for_nan(val_dataset)\n",
    "    check_for_nan(test_dataset)\n",
    "\n",
    "    num_features = test_dataset[0].x.shape[1]  # Number of features per node\n",
    "    num_targets = test_dataset[0].y.shape[0]\n",
    "\n",
    "    detail_list = [num_features, num_targets]\n",
    "\n",
    "    # train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    # val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    return test_loader, detail_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b244b4d2-e73b-4ab1-9d1f-5efff4dda0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"../Data/FinalSplits\"\n",
    "norm_string=\"\"\n",
    "target=\"TER\"\n",
    "data_dirs = {}\n",
    "for data_type in ['TER', 'VEGF', 'Both']:\n",
    "    data_dirs[f\"Train_{data_type}\"] = f\"{data}/Train_{data_type}{norm_string}.pkl\"\n",
    "    data_dirs[f\"Valid_{data_type}\"] = f\"{data}/Valid_{data_type}{norm_string}.pkl\"\n",
    "    data_dirs[f\"Test_{data_type}\"] = f\"{data}/Test_{data_type}{norm_string}.pkl\"\n",
    "\n",
    "test_loader, data_details = get_loaders(data_dirs, target, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8bfb938-7667-46e1-a028-6cdf547484bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GCN_G3_D2(\n",
       "  (conv1): GATv2Conv(77, 128, heads=8)\n",
       "  (norm1): BatchNorm(1024)\n",
       "  (conv2): GATv2Conv(1024, 128, heads=8)\n",
       "  (norm2): BatchNorm(1024)\n",
       "  (conv3): GATv2Conv(1024, 1, heads=1)\n",
       "  (norm3): BatchNorm(1)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (linear1): Linear(in_features=1, out_features=128, bias=True)\n",
       "  (linear2): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import GNN.src.gnn_multiple as GCNs\n",
    "model_constructors = {\n",
    "    \"G2_D2\": GCNs.GCN_G2_D2,\n",
    "    \"G2_D3\": GCNs.GCN_G2_D3,\n",
    "    \"G2_D4\": GCNs.GCN_G2_D4,\n",
    "    \"G2_D5\": GCNs.GCN_G2_D5,\n",
    "    \"G3_D2\": GCNs.GCN_G3_D2,\n",
    "    \"G3_D3\": GCNs.GCN_G3_D3,\n",
    "    \"G3_D4\": GCNs.GCN_G3_D4,\n",
    "    \"G3_D5\": GCNs.GCN_G3_D5,\n",
    "    \"G4_D2\": GCNs.GCN_G4_D2,\n",
    "    \"G4_D3\": GCNs.GCN_G4_D3,\n",
    "    \"G4_D4\": GCNs.GCN_G4_D4,\n",
    "    \"G4_D5\": GCNs.GCN_G4_D5,\n",
    "    \"G5_D2\": GCNs.GCN_G5_D2,\n",
    "    \"G5_D3\": GCNs.GCN_G5_D3,\n",
    "    \"G5_D4\": GCNs.GCN_G5_D4,\n",
    "    \"G5_D5\": GCNs.GCN_G5_D5\n",
    "}\n",
    "\n",
    "model_class = model_constructors[\"G3_D2\"]\n",
    "standard_model = model_class(*data_details)\n",
    "standard_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3885881a-c2ad-4318-aa91-107a0ca60086",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Modular_GCN(\n",
       "  (gats): ModuleList(\n",
       "    (0): GATv2Conv(77, 128, heads=8)\n",
       "    (1): GATv2Conv(1024, 128, heads=8)\n",
       "    (2): GATv2Conv(1024, 1, heads=1)\n",
       "  )\n",
       "  (b_norms): ModuleList(\n",
       "    (0-1): 2 x BatchNorm(1024)\n",
       "    (2): BatchNorm(1)\n",
       "  )\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (dense_head): ModuleList(\n",
       "    (0): Linear(in_features=1, out_features=128, bias=True)\n",
       "    (1): Linear(in_features=128, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from GNN.src.gnn_modular import Modular_GCN\n",
    "modular_gcn = Modular_GCN(*data_details)\n",
    "modular_gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f656093c-f7ec-4ea1-b2bc-157ff5752fc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QBAM GNN",
   "language": "python",
   "name": "qbam_gnn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
